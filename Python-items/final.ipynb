{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4c9d3be",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f190d649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nithintata/opt/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/nithintata/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Python available modulses\n",
    "import glob\n",
    "import os\n",
    "import textract\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import isfile, join\n",
    "from io import StringIO\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "\n",
    "# Developed Module\n",
    "import text_process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e183b7a",
   "metadata": {},
   "source": [
    "## Global Variables to store resume paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffd97056",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_list = [] # stores all resumes\n",
    "resume_list_pdf = [] # Captures files with pdf extension\n",
    "resume_list_doc = [] # Captures files with doc extension\n",
    "resume_list_docx = [] # Captures files with docx extension\n",
    " \n",
    "file_names = [] # STORES RESUME FILE NAMES\n",
    "job_desc_files = [] # stores jd paths\n",
    "\n",
    "#path = 'C:/Users/sampathi/PycharmProjects/Resume_Ranking/Automated-Resume-Ranking-System-master/Original_Resumes'\n",
    "path= '/Users/nithintata/Documents/GitHub/Capestone-project-group3/Original_Resumes'\n",
    "for file in glob.glob(path + '/*.pdf', recursive=True):\n",
    "    resume_list_pdf.append(file)\n",
    "for file in glob.glob('**/*.doc', recursive=True):\n",
    "    resume_list_doc.append(file)\n",
    "for file in glob.glob('**/*.docx', recursive=True):\n",
    "    resume_list_docx.append(file)\n",
    "\n",
    "resume_list = resume_list_doc + resume_list_docx + resume_list_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c08c3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "resume_list1=[]\n",
    "a=requests.get(\"https://firestore.googleapis.com/v1/projects/capestone-945f7/databases/(default)/documents/jobsApplied\").json()\n",
    "for aa in a[\"documents\"]:\n",
    "    resume_list1.append(aa[\"fields\"][\"url\"][\"stringValue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5a28b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://firebasestorage.googleapis.com/v0/b/capestone-945f7.appspot.com/o/eyBbM03W6x2ckvJemmjg%2FNithin%20Tatafront-end%20dev%20resume%20sample.pdf?alt=media&token=e5221fdc-4f57-45fc-b0c2-c6efe2b03e69',\n",
       " 'https://firebasestorage.googleapis.com/v0/b/capestone-945f7.appspot.com/o/0q1yyOoSTOQKSJt1yDeh%2FJaswanth%20TataFinal_CV.pdf?alt=media&token=9b192e75-9c27-4574-bf11-6d7f7ccc743d',\n",
       " 'https://firebasestorage.googleapis.com/v0/b/capestone-945f7.appspot.com/o/0q1yyOoSTOQKSJt1yDeh%2FNithin%20TataJaswanth.pdf?alt=media&token=dc2803f6-8101-4f4a-8869-fe6604ecf405',\n",
       " 'https://firebasestorage.googleapis.com/v0/b/capestone-945f7.appspot.com/o/z2sLDgTFqKtznZ49aFWM%2FNithin%20Tatasql%20dev%20resume%20sample.pdf?alt=media&token=4cc6b526-ece7-4981-b700-f4e086486e0b',\n",
       " 'https://firebasestorage.googleapis.com/v0/b/capestone-945f7.appspot.com/o/eyBbM03W6x2ckvJemmjg%2FNithin%20TataAlice%20Clark%20CV.pdf?alt=media&token=e7cf03b9-d784-4e4c-8496-925dd5953bf9',\n",
       " 'https://firebasestorage.googleapis.com/v0/b/capestone-945f7.appspot.com/o/z2sLDgTFqKtznZ49aFWM%2FNithin%20TataAlice%20Clark%20CV.pdf?alt=media&token=7001f21c-ee70-40f4-8843-95fa018ea2fe',\n",
       " 'https://firebasestorage.googleapis.com/v0/b/capestone-945f7.appspot.com/o/0q1yyOoSTOQKSJt1yDeh%2Fjaswanth%20tataResume%20(6).pdf?alt=media&token=5eafe03f-7dfc-455e-b631-d0aa7ca92478',\n",
       " 'https://firebasestorage.googleapis.com/v0/b/capestone-945f7.appspot.com/o/eyBbM03W6x2ckvJemmjg%2FJaswanth%20TataJalpaDave_CV.pdf?alt=media&token=268d550f-6e69-4c05-9bc3-fc1558eb6c13']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_list1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8286f9",
   "metadata": {},
   "source": [
    "## Extract and Preprocess the text in Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f72bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(files_list):\n",
    "    resumes = [] # Stores final processed resume files \n",
    "    for pdf_path in files_list:\n",
    "        text = ''\n",
    "        with open(pdf_path, 'rb') as fh:\n",
    "            # iterate over all pages of PDF document\n",
    "            for page in PDFPage.get_pages(fh, caching=True, check_extractable=True):\n",
    "                # creating a resoure manager\n",
    "                resource_manager = PDFResourceManager()\n",
    "\n",
    "                # create a file handle\n",
    "                fake_file_handle = StringIO()\n",
    "\n",
    "                # creating a text converter object\n",
    "                converter = TextConverter(\n",
    "                                    resource_manager, \n",
    "                                    fake_file_handle, \n",
    "                                    codec='utf-8', \n",
    "                                    laparams=LAParams()\n",
    "                            )\n",
    "\n",
    "                # creating a page interpreter\n",
    "                page_interpreter = PDFPageInterpreter(\n",
    "                                    resource_manager, \n",
    "                                    converter\n",
    "                                )\n",
    "\n",
    "                # process current page\n",
    "                page_interpreter.process_page(page)\n",
    "\n",
    "                # extract text\n",
    "                text += fake_file_handle.getvalue()\n",
    "                text = text.replace('\\n', ' ')\n",
    "                \n",
    "                # close open handles\n",
    "                converter.close()\n",
    "                fake_file_handle.close()\n",
    "            resumes.append(text_process.normalize(text))\n",
    "            \n",
    "    for name in resume_list:\n",
    "        temp = name.split('.')[0]\n",
    "        temp = temp.split('/')[-1]\n",
    "        file_names.append(temp)\n",
    "    df = {'Path':resume_list, 'File Name': file_names, 'Text':resumes}\n",
    "    data = pd.DataFrame(df)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e71af38",
   "metadata": {},
   "source": [
    "## Parsing the Job Description(jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cfb893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_loc = 'C:/Users/sampathi/PycharmProjects/Resume_Ranking/Automated-Resume-Ranking-System-master/Job_Description/'\n",
    "file_loc = '/Users/nithintata/Documents/GitHub/Capestone-project-group3/Original_Resumes/'\n",
    "def parsing_jd(jd_file_name):\n",
    "    path = file_loc + jd_file_name + '.txt'\n",
    "    for file in glob.glob(path, recursive=True):\n",
    "        if not file in job_desc_files: \n",
    "            job_desc_files.append(file)\n",
    "    with open(path, 'rt') as file:\n",
    "        jd = file.read()\n",
    "    jd = summarize(jd, word_count=200)\n",
    "    file.close()\n",
    "    jd = text_process.normalize(jd)\n",
    "    \n",
    "#     dict = {'Path':path, 'File Name': jd_file_name, 'Text':jd}\n",
    "#     df = pd.DataFrame(dict)\n",
    "    \n",
    "    df = pd.DataFrame(columns=['Path', 'File Name', 'Text'])\n",
    "    df.loc[0] = [path, jd_file_name, jd]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af49aa15",
   "metadata": {},
   "source": [
    "## Return the resumes close to JD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6ce3e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_df(files_list, jd_file_name):\n",
    "    \n",
    "    df1 = extract_text_from_pdf(files_list)\n",
    "    df2 = parsing_jd(jd_file_name)\n",
    "    df3 = pd.concat([df1, df2], ignore_index = True)\n",
    "    \n",
    "    tfidfVect = TfidfVectorizer()\n",
    "    tfidf = tfidfVect.fit_transform(df3['Text'])\n",
    "    job_desc = df3[df3['File Name'] == jd_file_name]\n",
    "    \n",
    "    jd_tfidfVect = TfidfVectorizer()\n",
    "    jd_tfidfVect = jd_tfidfVect.fit(df3['Text'])\n",
    "    jd_tfidf = jd_tfidfVect.transform(job_desc['Text'])\n",
    "    \n",
    "#     feature_array = np.array(feature_names)\n",
    "#     tfidf_sorting = np.argsort(jd_tfidf.toarray()).flatten()[::-1]\n",
    "#     top_n = feature_array[tfidf_sorting][:10]\n",
    "    \n",
    "    nbrs = NearestNeighbors(n_neighbors=5).fit(tfidf)\n",
    "    distances, indices = nbrs.kneighbors(jd_tfidf)\n",
    "    names_similar = pd.Series(indices.flatten()).map(df3.reset_index()['File Name'])\n",
    "    result = pd.DataFrame({'Distance':distances.flatten(), 'Resume':names_similar})\n",
    "    \n",
    "    return result[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b489a3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eyBbM03W6x2ckvJemmjg%2FNithin%20Tatafront-end%20dev%20resume%20sample.pdf\n",
      "Cpmpleted\n",
      "0q1yyOoSTOQKSJt1yDeh%2FJaswanth%20TataFinal_CV.pdf\n",
      "Cpmpleted\n",
      "0q1yyOoSTOQKSJt1yDeh%2FNithin%20TataJaswanth.pdf\n",
      "Cpmpleted\n",
      "z2sLDgTFqKtznZ49aFWM%2FNithin%20Tatasql%20dev%20resume%20sample.pdf\n",
      "Cpmpleted\n",
      "eyBbM03W6x2ckvJemmjg%2FNithin%20TataAlice%20Clark%20CV.pdf\n",
      "Cpmpleted\n",
      "z2sLDgTFqKtznZ49aFWM%2FNithin%20TataAlice%20Clark%20CV.pdf\n",
      "Cpmpleted\n",
      "0q1yyOoSTOQKSJt1yDeh%2Fjaswanth%20tataResume%20(6).pdf\n",
      "Cpmpleted\n",
      "eyBbM03W6x2ckvJemmjg%2FJaswanth%20TataJalpaDave_CV.pdf\n",
      "Cpmpleted\n"
     ]
    }
   ],
   "source": [
    "#resume_list\n",
    "import tempfile\n",
    "for file_url in zip(resume_list1,range(0,len(resume_list1))):\n",
    "    response=requests.get(file_url[0])\n",
    "    #fine_name=os.path.join(tempfile.gettempdir(),\"hello\"+str(file_url[1]))\n",
    "    fine_name=\"hello\"+str(file_url[1])+\".pdf\"\n",
    "    print(file_url[0].split(\"/\")[-1].split(\"?\")[0])\n",
    "    with open(fine_name, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(\"Cpmpleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b5b9a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eyBbM03W6x2ckvJemmjg%2FNithin%20Tatafront-end%20dev%20resume%20sample.pdf'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_list1[0].split(\"/\")[-1].split(\"?\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92b6895c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-6b2a94b33cd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresume_list2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"hello1.pdf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"hello2.pdf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"hello3.pdf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"hello4.pdf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"hello5.pdf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"hello6.pdf\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"hello7.pdf\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresume_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_list2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sample'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-0f0355f3b759>\u001b[0m in \u001b[0;36mresume_df\u001b[0;34m(files_list, jd_file_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mresume_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjd_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_text_from_pdf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mdf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsing_jd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjd_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdf3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-889d8637396f>\u001b[0m in \u001b[0;36mextract_text_from_pdf\u001b[0;34m(files_list)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mfile_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'Path'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mresume_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'File Name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Text'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mresumes\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         ]\n\u001b[0;32m--> 287\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays must all be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    }
   ],
   "source": [
    "resume_list2=[\"hello1.pdf\",\"hello2.pdf\",\"hello3.pdf\",\"hello4.pdf\",\"hello5.pdf\",\"hello6.pdf\",\"hello7.pdf\"]\n",
    "resume_df(resume_list2, 'sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4c0448",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "### Skill API \n",
    "### Score with Phrase Matching\n",
    "### Suggested Job Titles\n",
    "### Distance, Cosine Similarity, Lavensh Distance, Resume, Jod desc ID, Resume ID, Overall score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
