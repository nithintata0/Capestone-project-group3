{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4c9d3be",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f190d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python available modulses\n",
    "import glob\n",
    "import os\n",
    "import textract\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import isfile, join\n",
    "from io import StringIO\n",
    "from collections import Counter\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "\n",
    "# Developed Module\n",
    "import text_process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e183b7a",
   "metadata": {},
   "source": [
    "## Global Variables to store resume paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffd97056",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_list = [] # stores all resumes\n",
    "resume_list_pdf = [] # Captures files with pdf extension\n",
    "resume_list_doc = [] # Captures files with doc extension\n",
    "resume_list_docx = [] # Captures files with docx extension\n",
    " \n",
    "file_names = [] # STORES RESUME FILE NAMES\n",
    "job_desc_files = [] # stores jd paths\n",
    "\n",
    "path = 'C:/Users/sampathi/PycharmProjects/Resume_Ranking/Automated-Resume-Ranking-System-master/Original_Resumes'\n",
    "for file in glob.glob(path + '/*.pdf', recursive=True):\n",
    "    resume_list_pdf.append(file)\n",
    "for file in glob.glob('**/*.doc', recursive=True):\n",
    "    resume_list_doc.append(file)\n",
    "for file in glob.glob('**/*.docx', recursive=True):\n",
    "    resume_list_docx.append(file)\n",
    "\n",
    "resume_list = resume_list_doc + resume_list_docx + resume_list_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "42309375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(resume_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8286f9",
   "metadata": {},
   "source": [
    "## Extract and Preprocess the text in Resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f72bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(files_list):\n",
    "    resumes = [] # Stores final processed resume files \n",
    "    for pdf_path in files_list:\n",
    "        text = ''\n",
    "        with open(pdf_path, 'rb') as fh:\n",
    "            # iterate over all pages of PDF document\n",
    "            for page in PDFPage.get_pages(fh, caching=True, check_extractable=True):\n",
    "                # creating a resoure manager\n",
    "                resource_manager = PDFResourceManager()\n",
    "\n",
    "                # create a file handle\n",
    "                fake_file_handle = StringIO()\n",
    "\n",
    "                # creating a text converter object\n",
    "                converter = TextConverter(\n",
    "                                    resource_manager, \n",
    "                                    fake_file_handle, \n",
    "                                    codec='utf-8', \n",
    "                                    laparams=LAParams()\n",
    "                            )\n",
    "\n",
    "                # creating a page interpreter\n",
    "                page_interpreter = PDFPageInterpreter(\n",
    "                                    resource_manager, \n",
    "                                    converter\n",
    "                                )\n",
    "\n",
    "                # process current page\n",
    "                page_interpreter.process_page(page)\n",
    "\n",
    "                # extract text\n",
    "                text += fake_file_handle.getvalue()\n",
    "                text = text.replace('\\n', ' ')\n",
    "                \n",
    "                # close open handles\n",
    "                converter.close()\n",
    "                fake_file_handle.close()\n",
    "            resumes.append(text_process.normalize(text))\n",
    "            \n",
    "    for name in resume_list:\n",
    "        temp = name.split('.')[0]\n",
    "        temp = temp.split('\\\\')[1]\n",
    "        file_names.append(temp)\n",
    "    df = {'Path':resume_list, 'File Name': file_names, 'Text':resumes}\n",
    "    data = pd.DataFrame(df)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e71af38",
   "metadata": {},
   "source": [
    "## Parsing the Job Description(jd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3cfb893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_loc = 'C:/Users/sampathi/PycharmProjects/Resume_Ranking/Automated-Resume-Ranking-System-master/Job_Description/'\n",
    "\n",
    "def parsing_jd(jd_file_name):\n",
    "    path = file_loc + jd_file_name + '.txt'\n",
    "    for file in glob.glob(path, recursive=True):\n",
    "        if not file in job_desc_files: \n",
    "            job_desc_files.append(file)\n",
    "    with open(path, 'rt') as file:\n",
    "        jd = file.read()\n",
    "    jd = summarize(jd, word_count=200)\n",
    "    file.close()\n",
    "    jd = text_process.normalize(jd)\n",
    "    \n",
    "#     dict = {'Path':path, 'File Name': jd_file_name, 'Text':jd}\n",
    "#     df = pd.DataFrame(dict)\n",
    "    \n",
    "    df = pd.DataFrame(columns=['Path', 'File Name', 'Text'])\n",
    "    df.loc[0] = [path, jd_file_name, jd]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af49aa15",
   "metadata": {},
   "source": [
    "## Return the resumes close to JD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6ce3e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resume_df(files_list, jd_file_name):\n",
    "    \n",
    "    df1 = extract_text_from_pdf(files_list)\n",
    "    df2 = parsing_jd(jd_file_name)\n",
    "    df3 = pd.concat([df1, df2], ignore_index = True)\n",
    "    \n",
    "    tfidfVect = TfidfVectorizer()\n",
    "    tfidf = tfidfVect.fit_transform(df3['Text'])\n",
    "    job_desc = df3[df3['File Name'] == jd_file_name]\n",
    "    \n",
    "    jd_tfidfVect = TfidfVectorizer()\n",
    "    jd_tfidfVect = jd_tfidfVect.fit(df3['Text'])\n",
    "    jd_tfidf = jd_tfidfVect.transform(job_desc['Text'])\n",
    "    \n",
    "#     feature_array = np.array(feature_names)\n",
    "#     tfidf_sorting = np.argsort(jd_tfidf.toarray()).flatten()[::-1]\n",
    "#     top_n = feature_array[tfidf_sorting][:10]\n",
    "    \n",
    "    nbrs = NearestNeighbors(n_neighbors=5).fit(tfidf)\n",
    "    distances, indices = nbrs.kneighbors(jd_tfidf)\n",
    "    names_similar = pd.Series(indices.flatten()).map(df3.reset_index()['File Name'])\n",
    "    result = pd.DataFrame({'Distance':distances.flatten(), 'Resume':names_similar})\n",
    "    \n",
    "    return result[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b489a3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b6895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_df(resume_list, 'sample1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4c0448",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "### Skill API \n",
    "### Score with Phrase Matching\n",
    "### Suggested Job Titles\n",
    "### Distance, Cosine Similarity, Lavensh Distance, Resume, Jod desc ID, Resume ID, Overall score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
